{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee0d9bf",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566bc0c",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f3c2a",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6bebf",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b35c13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: wheel in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from lightgbm) (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from lightgbm) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.10.6)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (67.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "2023-03-13 19:27:44.300292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-03-13 19:27:44.300316: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-13 19:27:46.479968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-03-13 19:27:46.480559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2023-03-13 19:27:46.481132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2023-03-13 19:27:46.481700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2023-03-13 19:27:46.482271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2023-03-13 19:27:46.482843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2023-03-13 19:27:46.483411: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2023-03-13 19:27:46.483975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2023-03-13 19:27:46.483988: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.20.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\matro\\anaconda3\\envs\\practicum\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;3m[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use\n",
      "the full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\matro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\matro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# подготавливаем рабочее пространство,\n",
    "# загружаем библиотеки\n",
    "!pip install lightgbm\n",
    "!pip install spacy\n",
    "!spacy download en\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score, make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# настройки\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# константы\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e26e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгрузим наш датасет\n",
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a591af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удалим лишний столбец и вывидем первые 5 строк\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a3e6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на размер датасета\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeaa5cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# скопируем наш датасет в переменную corpus для дальнейшей работы\n",
    "corpus = df.copy()\n",
    "corpus['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f464a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [27:49<00:00, 95.40it/s]  \n"
     ]
    }
   ],
   "source": [
    "# лемматизируем наши тексты оставив лишь необходимое\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    lemm_text = \" \".join([token.lemma_ for token in doc])\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return \" \".join(cleared_text.split())\n",
    "\n",
    "corpus['lemm_text'] = corpus['text'].progress_apply(lemmatize_text)\n",
    "\n",
    "corpus = corpus.drop('text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37303b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour I be see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man I be really not try to edit war it be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>more I can not make any real suggestion on imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                          lemm_text\n",
       "0      0  explanation why the edit make under my usernam...\n",
       "1      0  d aww he match this background colour I be see...\n",
       "2      0  hey man I be really not try to edit war it be ...\n",
       "3      0  more I can not make any real suggestion on imp...\n",
       "4      0  you sir be my hero any chance you remember wha..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на результат\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5a7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делим данные на признаки и таргет\n",
    "X = corpus['lemm_text']\n",
    "y = corpus['toxic']\n",
    "\n",
    "# делим выборки на обучающие и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4fa4784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Размер тренировочной выборки: 143362 строк'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Размер тренировочного целевого признака: 143362 строк'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Размер тестовой выборки: 15930 строки'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Размер тестового целевого признака: 15930 строки'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# проверим размеры наших выборок\n",
    "display(f'Размер тренировочной выборки: {X_train.shape[0]} строк')\n",
    "display(f'Размер тренировочного целевого признака: {y_train.shape[0]} строк')\n",
    "display(f'Размер тестовой выборки: {X_test.shape[0]} строки')\n",
    "display(f'Размер тестового целевого признака: {y_test.shape[0]} строки')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeed814",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d5eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с помощью make_pipeline напишем функцию для векторизации и подбора параметров через grid\n",
    "def pipe(model, params):\n",
    "    pipeline = make_pipeline(TfidfVectorizer(stop_words=list(stopwords)), model)\n",
    "    grid = GridSearchCV(pipeline,\n",
    "                        param_grid=params,\n",
    "                        n_jobs=-1,\n",
    "                        verbose=1,\n",
    "                        scoring='f1',\n",
    "                        cv=2)\n",
    "    return grid\n",
    "\n",
    "\n",
    "# напишем функцию для обучения модели с подобранными параметрами и выводом лучшего f1_score\n",
    "def fit_best_model(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    best_score = model.best_score_\n",
    "    best_model = model.best_estimator_\n",
    "    display(f'Параметры лучшей модели: {model.best_params_}')\n",
    "    display(f'F1 лучшей модели: {best_score}')\n",
    "    return best_model, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b23fb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Параметры лучшей модели: {'logisticregression__C': 10}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1 лучшей модели: 0.7639288339441943'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.4 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# подберем параметры и выведем на экран f1 для модели LogisticRegression\n",
    "\n",
    "params_LR = {'logisticregression__C': np.arange(5, 15, 1)}\n",
    "\n",
    "grid_LR = pipe(LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, class_weight='balanced'), params_LR)\n",
    "\n",
    "model_LR, best_score_LR = fit_best_model(grid_LR, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a169b301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Параметры лучшей модели: {'decisiontreeclassifier__max_depth': 50}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1 лучшей модели: 0.7053280558652326'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 36.8 s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# подберем параметры и выведем на экран f1 для модели DecisionTreeClassifier\n",
    "\n",
    "params_DTC = {'decisiontreeclassifier__max_depth': np.arange(2, 51, 2)}\n",
    "\n",
    "grid_DTC = pipe(DecisionTreeClassifier(random_state=RANDOM_STATE), params_DTC)\n",
    "\n",
    "model_DTC, best_score_DTC = fit_best_model(grid_DTC, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2327b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Параметры лучшей модели: {'lgbmclassifier__learning_rate': 0.1, 'lgbmclassifier__num_leaves': 100}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'F1 лучшей модели: 0.7723774385185529'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 5s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# подберем параметры и выведем на экран f1 для модели LGBMClassifier\n",
    "\n",
    "params_LGBMC = {'lgbmclassifier__num_leaves': [100, 150, 200], \n",
    "                'lgbmclassifier__learning_rate': [.1, .2]}\n",
    "\n",
    "grid_LGBMC = pipe(LGBMClassifier(random_state=RANDOM_STATE), params_LGBMC)\n",
    "\n",
    "model_LGBMC, best_score_LGBMC = fit_best_model(grid_LGBMC, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c5f3a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.763929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.705328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.772377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              f1\n",
       "LogisticRegression      0.763929\n",
       "DecisionTreeClassifier  0.705328\n",
       "LGBMClassifier          0.772377"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем на экран таблицу с итогами исследования\n",
    "models = ['LogisticRegression', 'DecisionTreeClassifier', 'LGBMClassifier']\n",
    "table = pd.DataFrame(np.array([best_score_LR, best_score_DTC, best_score_LGBMC]), index=models)\n",
    "table.set_axis(['f1'], axis=1, inplace=True)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7941e6c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке для модели LGBMClassifier: 0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "# проверим f1 на тестовой выборке и моделе model_LGBMC\n",
    "predict_LGBMC = model_LGBMC.predict(X_test)\n",
    "print(f'f1 на тестовой выборке для модели LGBMClassifier: {f1_score(y_test, predict_LGBMC)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03ea65",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5707f",
   "metadata": {},
   "source": [
    "Подготовим тексты с помощью предобученной на токсичных комментариях BERT. И посчитаем метрику f1 на предсказаниях линейной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a6d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем библиотеки\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09a1c28a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# загружаем tokenizer и model для предобученной на токсик текстах нейросети bert\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "model = transformers.BertModel.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c627475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим 1000 записей из датасета чтобы код быстрее отработал\n",
    "df_for_bert = df.sample(1000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10f61ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведем тексты в токены\n",
    "tokenized = df_for_bert['text'].apply((lambda x: tokenizer.encode(x, \n",
    "                                                                  add_special_tokens=True, \n",
    "                                                                  max_length=512, \n",
    "                                                                  truncation=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c7851b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в меньших строках заполним пропуски нулями чтобы все имели одну длину\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "165f8b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим доступность видеочипа\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b34d232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff5dccde70b4d34b538a9c8711a9ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# обработаем датасет батчами по 100\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e87c2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим признаки и таргет\n",
    "X_bert = np.concatenate(embeddings)\n",
    "y_bert = df_for_bert['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3e6d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делим на train и test\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(X_bert, \n",
    "                                                                        y_bert, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ae9deba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8803571428571428"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 469 ms\n",
      "Wall time: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# подберем лучшие параметры для модели LogisticRegression\n",
    "# выведем на экран лучшие параметры и f1\n",
    "\n",
    "LR = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "params_LR = {\n",
    "    'C': np.arange(5, 15, 1)\n",
    "}\n",
    "\n",
    "grid_LR_bert = GridSearchCV(LR,\n",
    "                            param_grid=params_LR,\n",
    "                            cv=2,\n",
    "                            scoring='f1',\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_LR_bert.fit(X_train_bert, y_train_bert)\n",
    "\n",
    "model_LR_bert = grid_LR_bert.best_estimator_\n",
    "LR_bet_best_score = grid_LR_bert.best_score_\n",
    "\n",
    "display(grid_LR_bert.best_params_)\n",
    "display(LR_bet_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "652fa894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке для модели LGBMClassifier: 0.9500000000000001\n"
     ]
    }
   ],
   "source": [
    "# проверим f1 на тестовой выборке и моделе model_LR_bert\n",
    "predict_LR_bert = model_LR_bert.predict(X_test_bert)\n",
    "print(f'f1 на тестовой выборке для модели LGBMClassifier: {f1_score(y_test_bert, predict_LR_bert)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac8e29",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2617c",
   "metadata": {},
   "source": [
    "Модель LGBMClassifier решает поставленную задачу, с ее помощью мы преодалели границу f1=0.75. Из-за дисбаланса классов мы очень хорошо предсказуем больший и хуже меньший класс, смещение приоритета меньшему классу не принесло больших отличий от текущего результата."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237f3c1",
   "metadata": {},
   "source": [
    "Отдельно подготовили признаки с помощью BERT, взяли из датасета 1000 строк случайным образом. Результат линейной модели на признаках подготовленных BERT на тесте f1 = 0.95. Bert значительно превзошла стандартные tfidf методы."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
